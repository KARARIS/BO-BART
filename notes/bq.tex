
\documentclass[12pt]{article}
\usepackage{bm}
\newcommand{\x}{\bm{x}}
\usepackage{color}
\usepackage{amsmath}
\usepackage{authblk}
\usepackage{graphicx,psfrag,epsf}
\usepackage{hyperref}
\usepackage{enumerate}
\usepackage{natbib}
\usepackage{subcaption}
\let\cite\citep
\usepackage{colortbl}
\usepackage{soul}
\usepackage{url}
\usepackage{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}


\usepackage{bm}
\newcommand{\bx}{\bm{x}}
\newcommand{\bs}{\bm{s}}

\usepackage[toc,page]{appendix}

\usepackage{amsthm}

\newtheorem{theorem}{Theorem}
\makeatother


\title{Bayesian Quadrature algorithm proposal}
\date{\today}
\author{Seth Flaxman}
\usepackage[parfill]{parskip}

\begin{document}
\maketitle 

\section{BQ with BART}
We assume we have access to any easy to evaluate distribution $p(x)$, a costly to evaluate function $f(x)$,
and we wish to approximate the integral:
\begin{equation}
I_f \int f(x) p(x) dx
\label{eq:integral}
\end{equation}

We augment our tree data structure with the following information: 
for a given split, there is some probability
based on $p(x)$ of following the left path, and some probability $1-p(x)$ of following the right path. We store
these probabilities, so that for every terminal node $\rho_i$, we can calculate $p(\rho_i)$, the probability of the
event $\rho_i$, by multiplying the probabilities along the edges of the path by which we reached node $\rho_i$.

[INSERT FIGURE ILLUSTRATING THIS HERE]

We denote the value of terminal node $\rho_i$ by $f(\rho_i)$.
We further augment our tree data structure by calculating Eq.~\eqref{eq:integral} for the set of events that reach
each terminal node:
\begin{align}
& \int_{x \in \rho_i} f(x) p(x) dx \\
 &=  f(\rho_i) p(\rho_i)
\end{align}

Now given a set of trees $t_1, \ldots, t_T$ drawn from the posterior, we can use these trees to approximate
Eq.~\eqref{eq:integral}:
\begin{align}
I_f = \int f(x)p(x) dx \approx \frac{1}{T} \sum_{j=1}^T f(\rho_i^j) p(\rho_i^j)
\end{align}

After fitting BART, we calculate $I_f$ for each sum-of-trees drawn from the posterior.
If we draw $P$ samples, we obtain $I_f^{(1)}, \ldots, I_f^{(P)}$, allowing us to summarize
the mean and variance as:
\begin{equation}
	\mbox{E}[I_f] = \frac{1}{n} \sum_p I_f^{(p)}
\end{equation}
\begin{equation}
	\mbox{Var}[I_f] = \frac{1}{n^2} \sum_p (I_f^{(p)} - \mbox{E}[I_f])^2
\end{equation}

\section{Choosing the next query location (Sequential BQ with BART)}
Since it's not at all obvious how to take a Sequential Bayesian Quadrature with GPs approach to the BART setting,
a simple alternative is to look where the posterior variance in $f(x)$ as weighted by $p(x)$ is largest.
Thus, we choose as the next query location:
\begin{equation}
	x^* = \mbox{argmax}_{x} \mbox{Var}[f(x)p(x)]
	\label{eq:maxvar}
\end{equation}
To implement this in practice, we follow the BO with BART approach. Choose a set of test locations $x_1, \ldots, x_n$
using, e.g.~LHS and find the posterior predictve distribution of BART at each $x_i$:
\begin{equation}
	p(f(x_i) | \mathcal{D})
\end{equation}
Since we've used MCMC, what this means in practice is that we obtain a set of $p$ samples for each $x_i$: $f^{(1)}(x_i), \ldots, f^{(p)}(x_i)$ from the $p$ separate sum-of-trees. 
Now we can calculate the variance using the empirical estimator for mean and variance:
\begin{align}
	\mbox{E}[f(x_i)p(x_i)] &= \frac{1}{p} \sum_j f^{(j)}(x_i)p(x_i) \\
	\mbox{Var}[f(x_i)p(x_i)] &= \frac{1}{p} \sum_j \left[f^{(j)}(x_i)p(x_i) - \mbox{E}[f(x_i)p(x_i)]\right]^2
\end{align}
Finally, we find $x^*$ following Eq.~\eqref{eq:maxvar}.

\end{document}
